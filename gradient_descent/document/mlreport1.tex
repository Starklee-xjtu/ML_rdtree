%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% An example of a lab report write-up.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is a combination of several labs that I have done in the past for
% Computer Engineering, so it is not to be taken literally, but instead used as
% a great starting template for your own lab write up.  When creating this
% template, I tried to keep in mind all of the functions and functionality of
% LaTeX that I spent a lot of time researching and using in my lab reports and
% include them here so that it is fairly easy for students first learning LaTeX
% to jump on in and get immediate results.  However, I do assume that the
% person using this guide has already created at least a "Hello World" PDF
% document using LaTeX (which means it's installed and ready to go).
%
% My preference for developing in LaTeX is to use the LaTeX Plugin for gedit in
% Linux.  There are others for Mac and Windows as well (particularly MikTeX).
% Another excellent plugin is the Calc2LaTeX plugin for the OpenOffice suite.
% It makes it very easy to create a large table very quickly.
%
% Professors have different tastes for how they want the lab write-ups done, so
% check with the section layout for your class and create a template file for
% each class (my recommendation).
%
% Also, there is a list of common commands at the bottom of this document.  Use
% these as a quick reference.  If you'd like more, you can view the "LaTeX Cheat
% Sheet.pdf" included with this template material.
%
% (c) 2009 Derek R. Hildreth <derek@derekhildreth.com> http://www.derekhildreth.com
% This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/1.0/ or send a letter to Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305, USA.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[aps,letterpaper,10pt]{article}

\input kvmacros % For Karnaugh Maps (K-Maps)

\usepackage{graphicx} % For images
\usepackage{float}    % For tables and other floats
\usepackage{verbatim} % For comments and other
\usepackage{amsmath}  % For math
\usepackage{amssymb}  % For more math
\usepackage{fullpage} % Set margins and place page numbers at bottom center
\usepackage{listings} % For source code
\usepackage{xcolor}   % Source code colour
\usepackage{subfig}   % For subfigures

\usepackage{hyperref}           % For hyperlinks and indexing the PDF
\hypersetup{ % play with the different link colors here
    colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=blue % set to black to prevent printing blue links
}

\definecolor{mygrey}{gray}{.96} % Light Grey
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{mygrey},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=bl,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  %language=Python,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{orange},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  %title=myPython.py                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

% Make units a little nicer looking and faster to type
\newcommand{\Hz}{\textsl{Hz}}
\newcommand{\KHz}{\textsl{KHz}}
\newcommand{\MHz}{\textsl{MHz}}
\newcommand{\GHz}{\textsl{GHz}}
\newcommand{\ns}{\textsl{ns}}
\newcommand{\ms}{\textsl{ms}}
\newcommand{\s}{\textsl{s}}



% TITLE PAGE CONTENT %%%%%%%%%%%%%%%%%%%%%%%%
% Remember to fill this section out for each
% lab write-up.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\labtitle}{gradient descent method report}
\newcommand{\authorname}{Zixuan Li}
\newcommand{\professor}{Jianyong Sun}
\newcommand{\classno}{3118103163}
% END TITLE PAGE CONTENT %%%%%%%%%%%%%%%%%%%%


\begin{document}  % START THE DOCUMENT!


% TITLE PAGE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% If you'd like to change the content of this,
% do it in the "TITLE PAGE CONTENT" directly above
% this message
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}
\begin{center}
{\LARGE \textsc{optimization in big data research} \\ \vspace{4pt}}
{\Large \textsc{\labtitle} \\ \vspace{4pt}}
\rule[13pt]{\textwidth}{1pt} \\ \vspace{150pt}
{\large  \authorname \\ \vspace{10pt}
student number \classno\\ \vspace{10pt}
professor: \professor \\ \vspace{10pt}
\today}
\end{center}
\end{titlepage}
% END TITLE PAGE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\tableofcontents

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{research background}
%No Text Here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{research purpose}
\begin{comment}
This is a lab template which has a ton of different things which are useful in writing lab write-ups in the Computer Eningeering field.  This is demonstrating the comment block. Don't be overwhelmed, it may seem like a lot to take in at a time, but it's worth spending the time learning it.
\end{comment}

The purpose of this experiment is to optimize Beale function by using gradient descent, momentum, Nesterov accelerated gradient(NAG), and Adaptive Moment Estimation (Adam) algorithms.\vspace{3mm}

According to the definition by Khon nen, neural network is an extensive parallel interconnected network composed of simple units with adaptability, and its organization can simulate the interaction of biological nervous system with real world objects [ Koho nen, 1988 ]. In machine learning, the neural network means neural network leaning which is an interdisciplinanry field of study.\vspace{3mm}

The most basic component of the neural network is the neuron model. In the neural network, each neuron is connected to other neurons, and when it is stimulated, it will send signal to the other connected neurons. And the connection have different weight, thus has different impact on the other neurons. The total input value received by the neuron will be compared with the threshold value of the neuron and then processed by the activation function to produce the output of the neuron.
Training neural network is to give a training data set, and continuously adjust the transmission weight and activation function in the neural network to reduce the gap between the predicted value and the data set. If the error of the neural network in the training set is expressed by $\epsilon$ and it is obviously a function of the connection weight $\omega$ and the threshold value $\theta$ . At this time, the training process of the neural network can be regarded as a parameter optimization process. That is, in the parameter space, finding a set of optimal parameters makes $\epsilon$ minimum.\vspace{3mm}


Gradient descent is the most widely used parameter optimization method, in which we start from some initial solutions. In each iteration, we first calculate the gradient of the error function $\epsilon(x)$ at the current point and then determine the search direction according to the gradient. The learning rate $\eta$ determines the step of each iteration. Many deep learning project use various algorithms to optimize gradient descent, but in these large models, the optimization algorithm is often a black box model. Therefore, the purpose of this experiment is to optimize a test function by using several commonly used gradient descent algorithms, and to gain a more intuitive understanding of several gradient descent algorithms by writing code and visualizing the descent process.
\vspace{3mm}

The test function used in this research is Beale function:\vspace{3mm}
\begin{align*}
  f(x,y)=\left(1.5-x+xy\right)^{2}+\left(2.25-x+xy^{2}\right)^{2}
\end{align*}

Global minimum is $f(3,0.5)=0$ in search domain $-4.5\leq x,y\leq 4.5$.

\begin{figure}[H]
  \centering
  \label{fig:Beale1}\includegraphics[width=0.5\textwidth]{3dplot.png}\
  \caption{3d plot of Beale function }
\end{figure}

\begin{figure}[H]
  \centering
  \label{fig:Beale2}\includegraphics[width=0.8\textwidth]{contour.png}\
  \caption{contour plot of Beale function and global minimum}
\end{figure}



In this paper, Gradient descent, Momentum, Nesterov accelerated gradient, and Adaptive Moment Estimation will be used to solve the global lowest point of Beale Function. The characteristics of various gradient descent methods are known through experiments. The report will consist of the following five main parts:
\begin{itemize}
	\item Gradient descent method
	\item Momentum methods
	\item Nesterov accelerated gradient(NAG) method
  \item Adaptive Moment Estimation(ADAM) methon
	\item conclusion and Discussion
\end{itemize}
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Compile environment}
The Python language is used for experiments. The relevant compilation environment is as follows:
	\begin{itemize}
		\item OS：Windows 10
		\item Complier：python3.6
		\item numpy（scientific computing package）
		\item matplotlib（python visualize package）
	\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Procedure}

	\begin{enumerate}
		\item programming to visualize Beale function.
		\item programming the four algorithm.
		\item Adjust parameters in each algorithms, such as learning rate, to achieve fastest convergence rate.
		\item Run the program, examine the route of convergence to gain insight into each algorithm.
		\item Output related graphs and data
		\item Finish the experiment report.
	\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Gradient Descent Method}
\subsection{algorithm introduction}
The gradient descent method is very easy to understand. The gradient direction indicates the direction where the function grows fastest, so the opposite direction is the direction where the function decreases fastest. For the problem of machine learning model optimization, when we need to solve the minimum value, we can find the optimal value by moving in the direction of gradient descent.\vspace{3mm}


The main process of GD algorithm can be summarized as follows:

\begin{enumerate}
	\item input: Function to be solved$f(x,y)$, derivative of funcition to be solved${f(x,y)}'$, start point$P(x_0,y_0)$, the step size along the gradient descent direction $step$
	\item for $(abs(grad)> 1e-6)$ do
	\item compute the derivative of current point $P(x,y)$
  \item $gradient = -{f(P_t)}'$
	\item updated the next point as $P_{t+1}=P_t - step*gradient$
  \item end
	\item output: the convergence point $P_{convergence}$
\end{enumerate}


\subsection{result}
The start point as the exercise requirement is set at $P(3,4)$ . As for the step size , If it is less than $1 / L$. Then it can guarantee convergence (L is the Lipschitz constant of the gradient of the objective function).
\begin{align*}
  |f(x_1)-f(x_2)| = |{f(\xi)}'(x_1-x_2)| \leq L|x_1-x_2|
\end{align*}

I computed the numerical solution of Beale function's Lipschitz constant. And the result is $L=248533.18$. so as long as $dp \leq4\times10^{-6} $ the algorithm will convergence. After weighing convergence and convergence speed, I finally choose $step = 5\times10^{-6} $.

	\begin{figure}[H]
	  \centering
	  \label{fig:gd}\includegraphics[width=0.8\textwidth]{gd.png}\
	  \caption{gradient descent process}
	\end{figure}

\subsection{source code}
The part of source code of this algorithm is as follows.  \vspace{5mm}
	\lstinputlisting[language=Python, title=GD.py]{GD.py}
	\vspace{3mm}



\newpage
\section{Momentum Method}
\subsection{algorithm introduction}
As its name suggests, momentum acts as a constant catalyst for the previous optimization in the process of optimization. The influence of an already declining direction will not disappear immediately, but will decay in a certain form.\vspace{3mm}

The main process of Momentum algorithm can be summarized as follows:

\begin{enumerate}
	\item input: Function to be solved$f(x,y)$, derivative of funcition to be solved${f(x,y)}'$, start point$P(x_0,y_0)$, the step size along the gradient descent direction $step$, momentum term $\gamma$
	\item for $(abs(grad)> 1e-6)$ do
	\item compute the derivative of current point $x$
  \item compute update vector $v_t=\gamma v_{t-1} + step{f(x,y)}'$
	\item updated the next point as $P_{t+1}=P_t - v_t$
  \item end
	\item output: the convergence point $P_{convergence}$
\end{enumerate}
The momentum term $\gamma$ is usually set to 0.9.

\subsection{result}
The start point as the exercise requirement is set at $P(3,4)$ . As for the step size,After weighing convergence and convergence speed, I finally choose $step = 5\times10^{-7}$ .To restrict the iteraion time, the program is set to stop when it iteraes 10000 times.


	\begin{figure}[H]
	  \centering
	  \label{fig:momentum}\includegraphics[width=0.8\textwidth]{momentum.png}\
	  \caption{momentum descent process}
	\end{figure}

\subsection{source code}
The part of source code of this algorithm is as follows.  \vspace{5mm}
	\lstinputlisting[language=Python, title=momentum.py]{momentum.py}
	\vspace{3mm}


\newpage
\section{Nesterov accerlerated gradient Method}
\subsection{algorithm introduction}
  The momentum method can be thought as a ball rolling down a hill with momentum. Then the NAG method is smarter ball which can slowing down before climbing up another hill.\vspace{3mm}

  The main process of Momentum algorithm can be summarized as follows:
\begin{enumerate}
	\item input: Function to be solved$f(x,y)$, derivative of funcition to be solved${f(x,y)}'$, start point$P(x_0,x_0)$, the step size along the gradient descent direction $step$, momentum term $\gamma$
	\item for $(abs(grad)> 1e-6)$ do
	\item compute the derivative of current point ${f(P_t)}'$
  \item compute update vector $v_t=\gamma v_{t-1} + step{P_t-\gamma v_t-1}'$
	\item updated the next point as $P_{t+1}=P_t - v_t$
  \item end
	\item output: the convergence point $P_{convergence}$
\end{enumerate}

The difference between Nag and Momentum is that,  NAG use the momentum of present point to get a proximation of the next gradient rather than using the present gradient directly as Momentum method.


\subsection{result}
The start point as the exercise requirement is set at $P(3,4)$ . The momentum term $\gamma$ is also usually set to 0.9. The step size is same as momentum method $step = 5\times10^{-7}$. To restrict the iteraion time, the program is set to stop when it ierates 10000 times.

  \begin{figure}[H]
    \centering
    \label{fig:nag}\includegraphics[width=0.8\textwidth]{nag.png}\
    \caption{NAG descent process}
  \end{figure}

\subsection{source code}
The part of source code of this algorithm is as follows.  \vspace{5mm}
  \lstinputlisting[language=Python, title=nag.py]{nag.py}
	\vspace{3mm}


\newpage
\section{Adaptive Moment Estimation Method}
  \subsection{algorithm introduction}
  Adaptive Moment Estimation (Adam) is a method that computes adaptive learning rates for each parameter. Adaptive combines the advantages of RMSprop and Momentum method. It stores the an exponentially decaying average of past squared gradients $v_t$ and exponentially decaying average of past gradients $m_t$. \vspace{3mm}

  The main process of Momentum algorithm can be summarized as follows:

  \begin{enumerate}
  	\item input: Function to be solved$f(x,y)$, derivative of funcition to be solved${f(x,y)}'$, start point$P(3,4)$, the step size along the gradient descent direction $step$, super-parameter$\beta_1,\beta_2$ .
  	\item for $(abs(grad)> 1e-6)$ do
  	\item compute the gradient of current point $g_t=-{f(P_t)}'$
    \item compute the decaying averages of past gradient $m_t=\beta1 m_{t-1} +(1-\beta_1)g_t$
    \item compute the decaying averages of past squared gradient $v_t=\beta_2 v_{t-1} +(1-\beta_2)g_t^{2}$
    \item computing bias-corrected first moment estimates $\hat{m_t}=\frac{m_t}{1-\beta_1^(t)}$
    \item computing bias-corrected second moment estimates $\hat{v_t}=\frac{m_t}{1-\beta_2^(t)}$
    \item compute update vector $v_t=\frac{step}{\sqrt{\hat{v_t}+\epsilon}\hat{m_t}} $
    \item updated the next point as $P_{t+1}=P_t - v_t$
    \item end
  	\item output: the convergence point $P_{convergence}$
  \end{enumerate}




  \subsection{result}
  The default values proposed by the authors of this methd is $\beta_1=0.9, \beta_2=0.999, \epsilon=10^{-8}$
  And The start point as the exercise requirement is set at $P(3,4)$ . The step size is set to 1 by testing to have a relatively fast convergence rate. To restrict the iteraion time, the program is set to stop when it ierates 10000 times.

    \begin{figure}[H]
    	 \centering
    	 \label{fig:adam}\includegraphics[width=0.8\textwidth]{adam.png}\
    	 \caption{ADAM descent process}
    \end{figure}
  We can see that the Adam algorithm behaves like a heavy ball with friction because it stores an exponentially decaying average of past gradients.


    \subsection{source code}
    The part of source code of this algorithm is as follows.  \vspace{5mm}
    	\lstinputlisting[language=Python, title=adam.py]{adam.py}
    	\vspace{3mm}

\newpage
\listoffigures

\end{document} % DONE WITH DOCUMENT!
\begin{comment}



\newpage
\section{LLE}
\subsection{方法介绍}
局部线性嵌入（Locally Linear Embedding, 简称LLE）是流形学习的一种。与Isomap通过建立临近连接图再使用MDS方法降维的方法不同，LLE方法通过保持邻域样本之间的线性关系降维。即一个样本$x_1$可以通过邻域样本$x_i,x_j,x_k$线性表示的话，那么经过LLE降维后，该关系将继续保持。这使得LLE算法对于卷曲的manifold数据的处理非常有效，尤其是当噪声较小的时候。\vspace{3mm}

算法的主要过程可以总结如下：


\begin{enumerate}
	\item 输入：样本集$D={x_1,x_2,...,x_m}$，期望的低维空间维数n，临近参数k
	\item for i = 1,2,...,m do
	\item 确定$x_i$的k临近
	\item 通过$\min\limits_{1,...,m} \sum_{i = 1} ^m(\lVert x_i - \sum\limits_{j \in Q_i }(w_{ij}  x_j) \rVert)^2$ 求得对$x_i$线性重构的系数$w_ij$，$j \in Q_i$
	\item 对于$j \notin Q_i$，令$w_{ij}=0$
	\item endfor
	\item $M=(I-W)^T(I-W)$
	\item 对M进行特征分解
	\item 返回M的最小的n个特征值的特征向量
	\item 输出:样本集在特征向量对应的低维空间的投影
\end{enumerate}


但由于LLE算法先要寻找k邻近$O(mlog(m)nlog(k))$，再计算wight矩阵$O(mnk^3)$，然后建立低维度的表示$O(m^2)$。最后一项的计算复杂度$（m^2）$导致LLE对于大型的数据集的计算基本是无能为力的。
\subsection{实验介绍}
仿照sci-kit示例程序，本实验使用scikit的datasets库方法，生成经典的manifolding 数据“瑞士卷”样本，在空间中呈现卷曲的状态。然后使用LLE方法对数据样本进行了处理，输出了在新的低维空间上的数据分布。可视化结果如下：

	\begin{figure}[H]
	  \centering
	  \label{fig:Per3A}\includegraphics[width=0.8\textwidth]{LLE.png}\
	  \caption{LLE可视化结果}
	  \label{fig:oscil}
	\end{figure}

可以看出从图中看出，LLE方法很好的实现了对manifolding数据在低维空间的展开。

\subsection{源代码}
实验使用的源代码如下.  \vspace{5mm}
	\lstinputlisting{plot_swissroll.py}
	\vspace{3mm}




\newpage
\section{工程应用}
\subsection{背景介绍}
前文的样本均为人为产生的，有很好的特征可供演示各类算法的特点。本节将对实际工程中得信号进行降维，以达到工程目的。\\
旋转机械属于能源与动力工程领域中使用较为广泛的机械设备，而转子是其核心部件。转子系统在运行过程中的振动信号会因裂纹故障发生显著的的变化。本节通过使用机器学习方法，对Case Western Reserve University Bearing Data Center Website上的转子故障数据，实现对转子故障的分析诊断。
实验使用一台2hp Reliance电动马达进行，加速度数据在靠近和远离马达轴承的位置进行测量。使用电火花加工( EDM )在电机轴承上播种故障。本研究使用直径为0.007英寸到0.04英寸直径裂纹故障的转子数据。转子数据中包括出现故障的轴承以及正常的轴承安装到测试电机中，电机负载为0至3马力(电机转速为1797至1720 RPM )时的振动数据。共9个类别对应如下。
{'Normal': 0, 'B007': 1,'B014': 2,'B021': 3,'IR007': 4，'IR014': 5，'IR021': 6,'OR007@6': 7,'OR014@6': 8,'OR021@6': 9, }
  数字代表裂纹直径，如007为0.007英寸，字母B，IR(inner race)，OR(outer race)代表同一故障实验不同测点处的数据。

	\begin{figure}[H]
	  \centering
	  \label{fig:Per3A}\includegraphics[width=1.0\textwidth]{summary.png}\
	  \caption{故障信息表格}
	  \label{fig:oscil}
	\end{figure}


\vspace{3mm}

本研究以0,1,2马力负载时的时序信号作为训练集，3马力负载时的时序信号作为测试集，通过使用PCA降维，然后使用的机器学习算法Logistics Regression，实现multi-label classification任务，并对比降维前后的分类效果。

\subsection{实验介绍}
先对数据进行预处理，过程如下：
\begin{enumerate}
	\item 读入数据(load\_data)
	\item 切割数据(wave\_cut) 通过给定的时间窗大小(2048)和期望的sample数量(256)，将一个时序信号切割成对应的sample signal。
	\item 对信号增加白噪声（add\_noise）,实现数据增强，使得切割得到的数据更贴近于实际信号。
	\item 归一化（trans\_norm）
	\item FFT快速傅立叶变换（trans\_fft）实际是对数据的一次降维，将时序信号转化为有限个频域上的幅值。
\end{enumerate}
处理后的信号如下图
	\begin{figure}[H]
	  \centering
	  \label{fig:Per3A}\includegraphics[width=0.8\textwidth]{timesig.png}\
	  \caption{R014\_DE 的时序信号以及频域信号}
	  \label{fig:oscil}
	\end{figure}

	\begin{figure}[H]
	  \centering
	  \label{fig:Per3A}\includegraphics[width=0.8\textwidth]{whitnoise.png}\
	  \caption{R014\_DE 的时序信号以及频域信号}
	  \label{fig:oscil}
	\end{figure}

因为窗函数大小为2048，所以经过傅里叶变换，信号频域大小为1024。但是这些频率显然并不都是与故障相关的，直观上样本间方差较大的频率更有可能包含故障信息，因此对频域信号做PCA （主成分分析）来进一步降维，通过多次试验，取低维空间维数100，将振动数据转化为更低维子空间中信息更密集的样本点。然后分别使用sci\-kit库中的Logistics Regression进行训练和分类。 然后再使用未做PCA的样本进行训练和分类，得到实验结果。

PCA前分类正确率为：0.8826

PCA后分类正确率为：0.9004

可以看出，大幅压缩样本维度后，分类正确率并没有受到影响且有略微的提升。虽然分类正确率没有很高，但达到了基本的分类目的，用于工程实践还需要进一步的优化。


\subsection{源代码}
实验使用的源代码如下。（ 省略了data\_read读入数据部分） \vspace{5mm}
	\lstinputlisting{classify.py}
	\vspace{3mm}


\newpage
\section{结论与讨论}
实验的目的是通过使用代码，了解如何使用降维方法对数据进行降维，熟悉相关的编程环境以及调用方式。底层的算法实现并不是本实验的要求。

本文通过使用Sci-kit learn python库实现了三种机器学习算法的实验，尽管没有从最底层的代码进行实现，但是经过实验实现了三种降维算法的应用。PCA属于线性降维方法，KPCA属于非线性降维方法，LLE属于非线性降维方法中的流形学习方法。并对一个工程实际数据进行了分析，实现了基本的分类目标。通过实际的实验，对于降维的意义通过可视化有了更加直观的认识。对于算法原理也有了更深刻的认识。降维的线性与非线性方法的区别与特点也在实验中有所体现。如果之后有时间，会花更多时间，从底层代码完成三种机器学习算法，而不是单纯调库。

报告写作过程中参考了周志华《机器学习》,以及《Hands on machine learning with sci-kit learn》。代码demo部分来源于scikit-learn网站。

最后感谢孟教授这学期的教学，您的课干货满满，深入浅出。只是有些可惜课时太少，很希望未来机器学习这门课可以调整成全周的课程。顺颂时祺。

\end{document} % DONE WITH DOCUMENT!





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Experiment Data}
This section will consist of the important code blocks which were changed in order to meet the requirements of the lab.  \vspace{5mm}
	\lstinputlisting{code.c}
	\vspace{3mm}



% IF YOU'D RATHER TYPE THE CODE, OR HAVE A SMALLER BLOCK OF CODE, USE THIS:
%\begin{lstlisting}
%if(something)
%	do this
%else
%	do this
%\end{lstlisting}

%% THIS IS FROM A DIFFERENT CLASS, BUT DEMONSTRATES MATH MODE WELL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Formulas and Overall Descriptions Used}
This part of the laboratory was done for \href{http://www.byui.edu/catalog/2004-2005/class.asp1075.htm}{Feedback Control}.  Most of this laboratory's calculations were completed and compiled by the folks at Quanser (the manufacturer of the inverted pendulum) and will give the lab a good starting place.  Below are the state equation and gain values used initially in the lab:
	\[
	\begin{bmatrix}
	\dot{\alpha} \\
	\ddot{\alpha} \\
	\dot{\theta} \\
	\ddot{\theta} \\
	\end{bmatrix}
	=
	\begin{bmatrix}
	0 & 1 & 0 & 0 \\
	81.7 & 0 & 0 & -13.9 \\
	0 & 0 & 0 & 1 \\
	39.7 & 0 & 0 & -14.4 \\
	\end{bmatrix}
	\begin{bmatrix}
	\alpha \\
	\dot{\alpha} \\
	\theta \\
	\dot{\theta} \\
	\end{bmatrix}
	+
	\begin{bmatrix}
	0 \\
	24.5 \\
	0 \\
	25.4 \\
	\end{bmatrix}
	V
	\]

	\[
	K  =
	\begin{bmatrix}
	21 & 2.8 & -2.2 & -2.0 \\
	\end{bmatrix}
	\]

Other values, such as the $\frac{\mbox{Volts}}{\mbox{Degree}}$ and $\frac{\mbox{Degrees}}{\mbox{Volt}}$ were obtained by first determining the max angle of the pendulum on both extreme sides.

Using the max angles from above, these values were determined:
	\[
	\begin{array}{l l}
		\alpha = 0.062 \frac{\mbox{Volts}}{\mbox{Degree}} \\ \\
		\alpha = 15.105 \frac{\mbox{Degrees}}{\mbox{Volt}} \\
	\end{array}
	\]

I would also like to add that in order to calibrate $\alpha$ to get a perfect vertical $= 0$, a value of $0.09$ needed to be added.  The same applies to $\theta$ where $0.322$ needs to be added.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{DC Motor Transfer Function and Parameters}

Definitions:
	\begin{align*}
		\theta(t) =  Angular Position \\
		\dot{\theta}(t) =  Angular Velocity \\
		\triangle t = t_{10\%} - t_{90\%} \\
		90\% = e^{-t_{10\%}/\tau} \\
		10\% = e^{-t_{90\%}/\tau} \\
	\end{align*}

The Math:
	\begin{align*}
		\frac{s\theta(s)}{V_{a}(s)} = \frac{K}{s+P} \\
		\mbox{Let}\ V_{a}(s) = \frac{V_{0}}{s} \\  % If you'd like to have a space following any command, add "\" to the end as shown here.
		s\theta(s) = \frac{KV_{0}}{(S+P)S} = \frac{KV_{0}}{\frac{P}{S}} - \frac{\frac{KV_{0}}{P}}{s+P} \\
		L^{-1} \Rightarrow \dot{\theta}(t) = \frac{KV_{0}}{P}(1-e^{-t/(1/P)}) \\
		\dot{\theta}(t) = (\dot{\theta}_{i} - \dot{\theta}_{f})e^{-pt} + \dot{\theta}_{f} \\
	\end{align*}

Final equations:
	\begin{align}
		\label{thetadot}\dot{\theta}_{f} = \frac{KV_{0}}{P} \\
		\label{equ:tau}\frac{1}{P} = \tau = \frac{\triangle t}{ln(9)}
	\end{align}

Graphically (Refer to Equation \ref{thetadot} and Equation \ref{equ:tau}) :
	% Drawn and exported to png using Inkscape.
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.33\textwidth]{graph.png}
		\end{center}
	\label{graph}
	\end{figure}

% AGAIN, ANOTHER EXAMPLE FROM A DIFFERENT CLASS WHICH DEMONSTRasdATES KMAPS AND TABLES NICELY.
\newpage % I added this after viewing the completed pdf and decided to make this cosmetic change
This section consists of tables and reductions which were used in this laboratory exercise.

% This table was generated using the Calc2LaTeX macro which I mentioned earlier.
% You'll need OpenOffice installed and you'll have to download the macro online.
% If you're interested, I have a guide on how to set this up and use it on my
% blog.  http://www.derekhildreth.com/blog  Search for "LaTeX".  You'll find it.
	\begin{table}[htbp]
	\begin{center}
		\begin{tabular}{|ccc|cc|}
			\hline
			\textbf{PS} & \textbf{D} & \textbf{N} & \textbf{NS} & \textbf{P} \\ \hline
			\$0.00 & 0 & 0 & \$0.00 & 0 \\
			 & 0 & 1 & \$0.05 & 0 \\
			 & 1 & 0 & \$0.10 & 0 \\
			 & 1 & 1 & -- & -- \\ \hline
			\$0.05 & 0 & 0 & \$0.05 & 0 \\
			 & 0 & 1 & \$0.10 & 0 \\
			 & 1 & 0 & \$0.15 & 0 \\
			 & 1 & 1 & -- & -- \\ \hline
			\$0.10 & 0 & 0 & \$0.10 & 0 \\
			 & 0 & 1 & \$0.15 & 0 \\
			 & 1 & 0 & \$0.15 & 0 \\
			 & 1 & 1 & -- & -- \\ \hline
			\$0.15 & -- & -- & \$0.15 & 1 \\ \hline
			\end{tabular}
	\end{center}
	\caption{Symbolic Transition Table}
	\label{symbolic}
	\end{table}

	\begin{table}[H]
		\centering
		\subfloat[D1 = $Q_{1}$+D+$Q_{0}$N] % Caption
			{
				\karnaughmap{4}{D1:}{ {$Q_{1}$} {$Q_{0}$} {D} {N} }{001X011X111X111X}{}  % See the included kvdoc.pdf file for more details
			} \hspace{10mm} % seperate them a bit
		\subfloat[D0 = $\Bar{Q_{0}}$N + $Q_{0}\Bar{N}$ + $Q_{1}$N + $Q_{1}$D] % Caption
			{
				\karnaughmap{4}{D0:}{ {$Q_{1}$} {$Q_{0}$} {D} {N} }{010X101X011X111X}{}
			}
	  \caption{Karnaugh maps and the simplified results of the logic.}
	  \label{fig:kmaps}
	\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Discussion \& Conclusion}
The goal of this lab was to re-design the LED/Switch system to include a hardware timer.  By pressing eight different combinations of the three buttons, the LEDs on the board were to act in different ways using these timers. There was not a Q\&A requirement for this lab. \vspace{3mm} % I use this to seperate the paragraphs a bit.

I was able to accomplish the requirements of the lab by utilizing the \texttt{IntMgrTimerExample.c} project found within the analog devices example programs folder (and mentioned in the class lecture).  There were some stumbling blocks to overcome.  The most difficult for myself was actually getting the period of the LEDs just right.  I was able to get it very close to the 333.3\ms, 666.7\ms, and 1\s periods, but not exactly.  My first method of getting these periods right was to take the clock speed in \MHz, find the period by taking the inverse of the clock speed, and then solving for the value in hex that was needed to get the right period.  This didn't yeild very accurate results at all, and so I then went through a trial and error session until I got a value of 1.1\ms.  I used this value in hex to calculate the other periods.  The results of this method can be seen in Figure \ref{fig:oscil} above in the schematics section. \vspace{3mm}

Another observation I would like to point out is that I put all of my logic within the interrupts themselves.  I feel that this was a hacked way of doing the lab to save time and that it's probably not the best programming method.  After I was completed with my lab, I viewed other students solutions and they just seemed more elegant.  Interestingly enough, the other students weren't incredibly happy with their solution either.  If I were to go back and do this lab again, I would invest more time in both understanding how to utilze the interrupts as well as find a more elegant solution to blink the lights. \vspace{3mm}

All in all, this laboratory gave me an insight on how interrupts work and I hope to be able to apply them to following labs\ldots


\end{document} % DONE WITH DOCUMENT!


%%%%%%%%%%
PERSONAL FAVORITE LAB WRITE-UP STRUCTURE
%%%%%%%%%%
\section{Introduction}
	% No Text Here
	\subsection{Purpose}
		% Lab objective
	\subsection{Equipment}
		% Any and all equipment used (specific!)
	\subsection{Procedure}
		% Overview of the procedure taken (not-so-specific!)
\newpage
\section{Schematic Diagrams}
	% Any schematics, screenshots, block
   % diagrams used.  Possibly photos or
	% images could go here as well.
\newpage
\section{Experiment Data}
	% Depending on lab, program code would be
	% included here without the Estimated and
	% Actual Results.
	\subsection{Estimated Results}
		% Calculated. What it should be.
	\subsection{Actual Results}
		% Measured.  What it actually was.
\newpage
\section{Discussion \& Conclusion}
	% 3 Paragraphs:
		% Restate the objective of the lab
		% Discuss personal trials, errors, and difficulties
		% Conclude the lab


%%%%%%%%%%%%%%%%
COMMON COMMANDS:
%%%%%%%%%%%%%%%%
% IMAGES
begin{figure}[H]
   \begin{center}
      \includegraphics[width=0.6\textwidth]{RTL_SCHEM.png}
   \end{center}
\caption{A screenshot of the RTL Schematics produced from the Verilog code.}
\label{RTL}
\end{figure}

% SUBFIGURES IMAGES
\begin{figure}[H]
  \centering
  \subfloat[LED4 Period]{\label{fig:Per4}\includegraphics[width=0.4\textwidth]{period_led4.png}} \\
  \subfloat[LED5 Period]{\label{fig:Per5}\includegraphics[width=0.4\textwidth]{period_led5.png}}
  \subfloat[LED6 Period]{\label{fig:Per6}\includegraphics[width=0.4\textwidth]{period_led6.png}}
  \caption{Period of LED blink rate captured by osciliscope.}
  \label{fig:oscil}
\end{figure}

% INSERT SOURCE CODE
\lstset{language=Verilog, tabsize=3, backgroundcolor=\color{mygrey}, basicstyle=\small, commentstyle=\color{BrickRed}}
\lstinputlisting{MODULE.v}

% TEXT TABLE
\begin{table}
\begin{center}
\begin{tabular}{|l|c|c|l|}
	x & x & x & x \\ \hline
	x & x & x & x \\
	x & x & x & x \\ \hline
\end{tabular}
\caption{Caption}
\label{label}
\end{center}
\end{table}

% MATHMATICAL ENVIRONMENT
$ 8 = 2 \times 4 $

% CENTERED FORMULA
\[  \]

% NUMBERED EQUATION
\begin{equation}

\end{equation}

% ARRAY OF EQUATIONS (The splat supresses the numbering)
\begin{align*}

\end{align*}

% NUMBERED ARRAY OF EQUATIONS
\begin{align}

\end{align}

% ACCENTS
\dot{x} % dot
\ddot{x} % double dot
\bar{x} % bar
\tilde{x} % tilde
\vec{x} % vector
\hat{x} % hat
\acute{x} % acute
\grave{x} % grave
\breve{x} % breve
\check{x} % dot (cowboy hat)

% FONTS
\mathrm{text} % roman
\mathsf{text} % sans serif
\mathtt{text} % Typewriter
\mathbb{text} % Blackboard bold
\mathcal{text} % Caligraphy
\mathfrak{text} % Fraktur

\textbf{text} % bold
\textit{text} % italic
\textsl{text} % slanted
\textsc{text} % small caps
\texttt{text} % typewriter
\underline{text} % underline
\emph{text} % emphasized

\begin{tiny}text\end{tiny} % Tiny
\begin{scriptsize}text\end{scriptsize} % Script Size
\begin{footnotesize}text\end{footnotesize} % Footnote Size
\begin{small}text\end{small} % Small
\begin{normalsize}text\end{normalsize} % Normal Size
\begin{large}text\end{large} % Large
\begin{Large}text\end{Large} % Larger
\begin{LARGE}text\end{LARGE} % Very Large
\begin{huge}text\end{huge}   % Huge
\begin{Huge}text\end{Huge}   % Very Huge


% GENERATE TABLE OF CONTENTS AND/OR TABLE OF FIGURES
% These seem to have some issues with the "revtex4" document class.  To use, change
% the very first line of this document to "article" like this:
% \documentclass[aps,letterpaper,10pt]{article}
\tableofcontents
\listoffigures
\listoftables

% INCLUDE A HYPERLINK OR URL
\url{http://www.derekhildreth.com}
\href{http://www.derekhildreth.com}{Derek Hildreth's Website}

% FOR MORE, REFER TO THE "LINUX CHEAT SHEET.PDF" FILE INCLUDED!
